model_params:
  model: smp.Unet
  encoder_name: efficientnet-b2
  encoder_weights: imagenet
  classes: 4
  activation: null

args:
  logdir: "./logs/clouds_logs"
  seed: 65
  check: False
  verbose: True

distributed_params:
  opt_level: O2

stages:
  data_params:
    batch_size: 8
    num_workers: 4
    df_train_name: "train.csv"
    path: "../../input/dataset_320x640"
    image_folder: "train_images"
    model_name: efficientnet-b2

  state_params:
    main_metric: loss
    minimize_metric: true

  stage1:
    callbacks_params:
      custom_dice_10:
        callback: CustomDiceCallback

      dice_metric:
        callback: DiceCallback

      optimizer:
        callback: OptimizerCallback

      scheduler:
        callback: SchedulerCallback

      saver:
        callback: CheckpointCallback
        save_n_best: 2

      early_stop:
        callback: EarlyStoppingCallback
        patience: 5
        min_delta: 0.0005
        metric: loss

    state_params:
      num_epochs: 30

    criterion_params:
      criterion: BCEDiceLossCustom

    optimizer_params:
      optimizer: Adam
      layerwise_params:
        encoder.*:
          lr: 0.0002
        decoder.*:
          lr: 0.002

    scheduler_params:
      scheduler: ReduceLROnPlateau
      factor: 0.5
      patience: 1

  stage2:
    callbacks_params:
      custom_dice:
        callback: CustomDiceCallback

      dice_metric:
        callback: DiceCallback

      optimizer:
        callback: OptimizerCallback

      scheduler:
        callback: SchedulerCallback

      saver:
        callback: CheckpointCallback
        save_n_best: 2

      early_stop:
        callback: EarlyStoppingCallback
        patience: 5
        min_delta: 0.0005
        metric: loss

    state_params:
      num_epochs: 30

    criterion_params:
      criterion: SymmetricLovaszLoss

    optimizer_params:
      optimizer: Adam
      layerwise_params:
        encoder.*:
          lr: 0.0002
        decoder.*:
          lr: 0.0008

    scheduler_params:
      scheduler: ReduceLROnPlateau
      factor: 0.5
      patience: 1
